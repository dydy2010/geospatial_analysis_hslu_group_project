{"cells":[{"cell_type":"markdown","metadata":{"id":"yW-8i__-58pF"},"source":["# **Urban Infrastructure Stress Analysis:**\n","\n","Geospatial Data Analysis – HSLU Master’s Program\n"]},{"cell_type":"markdown","metadata":{"id":"xIppQvoiaJAR"},"source":["## Mount Google Drive in Collab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xb5gIlgDaQ_s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765541641104,"user_tz":-60,"elapsed":49846,"user":{"displayName":"SE G","userId":"10331445410003329269"}},"outputId":"c79f2f0f-bb5f-4bbf-8c92-4e510720a719"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Project base folder: /content/drive/MyDrive/Colab Notebooks/GEO Spatial Data Analysis\n","Raw data folder: /content/drive/MyDrive/Colab Notebooks/GEO Spatial Data Analysis/Data/raw\n","Processed data folder: /content/drive/MyDrive/Colab Notebooks/GEO Spatial Data Analysis/Data/processed\n","\n","❌ ERROR: RAW folder not found. Please check your BASE path.\n"]}],"source":["from google.colab import drive\n","from pathlib import Path\n","\n","# 1. Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# 2. Base path for the project (EDIT THIS ONLY)\n","BASE = Path(\"/content/drive/MyDrive/Colab Notebooks/GEO Spatial Data Analysis\")\n","\n","# 3. Data folders\n","DATA = BASE / \"Data\"\n","RAW = DATA / \"raw\"\n","PROC = DATA / \"processed\"\n","\n","print(\"Project base folder:\", BASE)\n","print(\"Raw data folder:\", RAW)\n","print(\"Processed data folder:\", PROC)\n","\n","# Check if raw folder exists\n","if RAW.exists():\n","    print(\"\\nFiles in RAW folder:\")\n","    for p in RAW.iterdir():\n","        print(\" -\", p.name)\n","else:\n","    print(\"\\n❌ ERROR: RAW folder not found. Please check your BASE path.\")\n"]},{"cell_type":"markdown","metadata":{"id":"tvzqSpuk9VhR"},"source":["## Importing the necessary libaries"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1765543155458,"user":{"displayName":"SE G","userId":"10331445410003329269"},"user_tz":-60},"id":"5RhWJVKT9xKe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9c479c0-a75a-4a31-dc41-0e9afcbe2afe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Imports loaded successfully.\n"]}],"source":["# =========================================================\n","# 0. IMPORTS\n","# =========================================================\n","\n","# --- Core Python Libraries ---\n","import pandas as pd\n","import numpy as np\n","\n","# --- File & Path Handling ---\n","from pathlib import Path\n","\n","# --- Geospatial Libraries (added later if needed) ---\n","import geopandas as gpd\n","from shapely.geometry import Point\n","from pyproj import Transformer\n","\n","# --- Visualization Libraries (if needed in Colab) ---\n","# import matplotlib.pyplot as plt\n","# import seaborn as sns\n","\n","# --- Machine Learning / Clustering (added later) ---\n","# from sklearn.cluster import KMeans\n","# from sklearn.preprocessing import StandardScaler\n","\n","# --- Utility ---\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","print(\"Imports loaded successfully.\")\n"]},{"cell_type":"markdown","metadata":{"id":"TFAyL3-B-G2Q"},"source":["## Loading and inspecting the raw data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xseh0MQ3-WSB"},"outputs":[],"source":["# =========================================================\n","# 2. LOAD AND INSPECT RAW DATA\n","# =========================================================\n","\n","import pandas as pd\n","\n","# 2.1 Define file paths (using RAW from Section 1)\n","traffic_path = RAW / \"traffic_data_cleaned.csv\"\n","pop_path     = RAW / \"population_raw.csv\"\n","quart_path   = RAW / \"str_stadtquartier_raw_for_join.csv\"\n","\n","print(\"Traffic file path :\", traffic_path)\n","print(\"Population path   :\", pop_path)\n","print(\"Quartier path     :\", quart_path)\n","\n","# 2.2 Traffic data (sample only, file is very large)\n","print(\"\\n=== TRAFFIC DATA (sample) ===\")\n","print(\"Approx. file size (GB):\", round(traffic_path.stat().st_size / 1e9, 3))\n","\n","traffic_sample = pd.read_csv(traffic_path, nrows=100_000)  # sample for inspection\n","print(\"Sample shape:\", traffic_sample.shape)\n","display(traffic_sample.head())\n","print(\"\\nTraffic columns:\\n\", traffic_sample.columns.tolist())\n","\n","# 2.3 Population data (load full)\n","print(\"\\n=== POPULATION DATA ===\")\n","population = pd.read_csv(pop_path)\n","print(\"Population shape:\", population.shape)\n","display(population.head())\n","print(\"\\nPopulation columns:\\n\", population.columns.tolist())\n","\n","# 2.4 Quartier lookup table\n","print(\"\\n=== QUARTIER LOOKUP TABLE ===\")\n","quartiers = pd.read_csv(quart_path)\n","print(\"Quartier table shape:\", quartiers.shape)\n","display(quartiers.head())\n","print(\"\\nQuartier columns:\\n\", quartiers.columns.tolist())\n"]},{"cell_type":"markdown","metadata":{"id":"JFDXTeHv-LGl"},"source":["### Traffic Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h7PSCNYzNe2l"},"outputs":[],"source":["# =========================================================\n","# 3A. TRAFFIC DATA PREPARATION\n","# =========================================================\n","\n","\n","# Use only the columns we need\n","traffic_cols = [\n","    \"measurement_site_id\",\n","    \"east_coordinate\",\n","    \"north_coordinate\",\n","    \"timestamp\",\n","    \"vehicle_count\"\n","]\n","\n","traffic_path = RAW / \"traffic_data_cleaned.csv\"\n","\n","# Load only the needed columns\n","traffic = pd.read_csv(\n","    traffic_path,\n","    usecols=traffic_cols,\n","    parse_dates=[\"timestamp\"]  # auto-parse datetime\n",")\n","\n","print(\"Traffic loaded.\")\n","traffic.head()\n"]},{"cell_type":"markdown","source":["| Column                  | Why we need it                                                     |\n","| ----------------------- | ------------------------------------------------------------------ |\n","| **measurement_site_id** | Groups all records from the same station; ensures unique locations |\n","| **east_coordinate**     | Needed to map station location into Zurich quarters                |\n","| **north_coordinate**    | Needed to map station location into Zurich quarters                                                     |\n","| **timestamp**           | Extract year (and later day/hour patterns if needed)               |\n","| **vehicle_count**       | The actual traffic value                                           |\n"],"metadata":{"id":"-ajVaUtzPye3"}},{"cell_type":"markdown","source":["Traffic Data Quality Checks"],"metadata":{"id":"fIz8L_I_QiEV"}},{"cell_type":"code","source":["# =========================================================\n","# 3A.4 TRAFFIC DATA QUALITY CHECKS\n","# =========================================================\n","\n","print(\"Checking missing values...\\n\")\n","missing = traffic.isna().sum()\n","print(missing)\n","\n","print(\"\\nChecking duplicates...\\n\")\n","duplicate_rows = traffic.duplicated().sum()\n","print(\"Total duplicate rows:\", duplicate_rows)\n","\n","print(\"\\nChecking unique measurement sites...\\n\")\n","print(\"Unique measurement_site_id:\", traffic[\"measurement_site_id\"].nunique())\n","\n","print(\"\\nChecking timestamp range...\\n\")\n","print(\"Min timestamp:\", traffic[\"timestamp\"].min())\n","print(\"Max timestamp:\", traffic[\"timestamp\"].max())\n","\n","print(\"\\nChecking coordinate sanity...\\n\")\n","print(\"East min/max:\", traffic[\"east_coordinate\"].min(), traffic[\"east_coordinate\"].max())\n","print(\"North min/max:\", traffic[\"north_coordinate\"].min(), traffic[\"north_coordinate\"].max())\n"],"metadata":{"id":"tRnBT87gQmtt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cleaning and saving a new file"],"metadata":{"id":"4e2JLtK9RE_O"}},{"cell_type":"code","source":["# =========================================================\n","# 3A.5 CLEAN TRAFFIC DATA (remove missing & duplicates)\n","# =========================================================\n","\n","traffic_clean = traffic.copy()\n","\n","# 1. Remove rows with missing vehicle_count\n","before_missing = traffic_clean.shape[0]\n","traffic_clean = traffic_clean.dropna(subset=[\"vehicle_count\"])\n","after_missing = traffic_clean.shape[0]\n","\n","print(f\"Removed {before_missing - after_missing} rows with missing vehicle_count.\")\n","\n","# 2. Remove duplicate rows\n","before_dupes = traffic_clean.shape[0]\n","traffic_clean = traffic_clean.drop_duplicates()\n","after_dupes = traffic_clean.shape[0]\n","\n","print(f\"Removed {before_dupes - after_dupes} duplicate rows.\")\n","\n","# 3. Reset index\n","traffic_clean = traffic_clean.reset_index(drop=True)\n","\n","traffic_clean.info()\n"],"metadata":{"id":"BEswirmLRHjL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =========================================================\n","# 3A.6 CONVERT COORDINATES FROM LV95 TO WGS84\n","# =========================================================\n","\n","# Create a transformer from Swiss LV95 (EPSG:2056) to WGS84 (EPSG:4326)\n","# LV95 uses East/North, WGS84 uses Lat/Lon\n","transformer = Transformer.from_crs(\"EPSG:2056\", \"EPSG:4326\", always_xy=True)\n","\n","print(\"Converting coordinates from LV95 (EPSG:2056) to WGS84 (EPSG:4326)...\")\n","\n","# Transform coordinates\n","# transformer.transform expects (x, y) which is (east, north) for LV95\n","# and returns (longitude, latitude) for WGS84\n","traffic_clean[\"longitude\"], traffic_clean[\"latitude\"] = transformer.transform(\n","    traffic_clean[\"east_coordinate\"].values,\n","    traffic_clean[\"north_coordinate\"].values\n",")\n","\n","print(\"Conversion complete!\")\n","print(\"\\nSample of converted coordinates:\")\n","display(traffic_clean[[\"measurement_site_id\", \"east_coordinate\", \"north_coordinate\",\n","                       \"longitude\", \"latitude\"]].head(10))\n","\n","# Quick sanity check: Zurich coordinates should be around:\n","# Latitude: ~47.37 (North)\n","# Longitude: ~8.54 (East)\n","print(\"\\nCoordinate ranges (should be in Zurich area):\")\n","print(f\"Latitude range: {traffic_clean['latitude'].min():.4f} to {traffic_clean['latitude'].max():.4f}\")\n","print(f\"Longitude range: {traffic_clean['longitude'].min():.4f} to {traffic_clean['longitude'].max():.4f}\")"],"metadata":{"id":"BN_HM2NCmdNA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clean_path = PROC / \"traffic_clean_small.csv\"\n","traffic_clean.to_csv(clean_path, index=False)\n","print(\"Saved cleaned file to:\", clean_path)\n"],"metadata":{"id":"790b59v_RR70"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6uyXyvC-EMFq"},"source":["### Population Data"]},{"cell_type":"code","source":["# 3B.1 Load population dataset\n","\n","pop_path = RAW / \"population_raw.csv\"\n","print(\"Population file path:\", pop_path)\n","\n","population = pd.read_csv(pop_path)\n","\n","population.head()\n","population.columns.tolist()\n","\n"],"metadata":{"id":"2uWG4v2IUTIN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Loding only the needed Column"],"metadata":{"id":"6KY-jfhcVR-X"}},{"cell_type":"code","source":["# Look at how categories are coded in the original dataset\n","population[\"SexCd\"].unique(), population[\"HerkunftCd\"].unique(), population[\"AlterV20ueber80Cd_noDM\"].unique()\n"],"metadata":{"id":"JX4M2lpoYv8u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["population_jan = population[population[\"StichtagDatMM\"] == 1]\n","population_jan.head()\n"],"metadata":{"id":"vbqtw8BHaDZ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# Inspect Demographic Categories in the Population Dataset\n","# This helps us understand how the dataset is split into\n","# demographic subgroups (sex, origin, age).\n","# We will use this to correctly aggregate total population.\n","# ============================================================\n","\n","# Check how sex is coded (male/female)\n","print(\"SEX CODES (SexCd):\")\n","print(population_jan[\"SexCd\"].value_counts())\n","print(\"\\n1 = male, 2 = female\")\n","\n","# Check how origin (Swiss/Foreign) is coded\n","print(\"\\nORIGIN CODES (HerkunftCd):\")\n","print(population_jan[\"HerkunftCd\"].value_counts())\n","print(\"\\n1 = Swiss, 2 = Foreign\")\n","\n","# Check age group codes\n","print(\"\\nAGE GROUP CODES (AlterV20ueber80Cd_noDM):\")\n","print(population_jan[\"AlterV20ueber80Cd_noDM\"].value_counts())\n","print(\"\\nAge groups 1–5 represent different age bands (e.g. 0–19, 20–39, etc.)\")\n","\n"],"metadata":{"id":"tyvg29g1aVGk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["NOTE:\n","Each quarter-year contains multiple demographic rows:\n","- 2 sexes × 2 origins × 5 age groups = 20 rows per quarter-year.\n","To obtain TRUE population, we must sum over all demographic categories"],"metadata":{"id":"m93HooQzbHXa"}},{"cell_type":"code","source":["# ============================================================\n","# 3B.4 Aggregate TRUE population per year & quarter (January only)\n","# We now:\n","# 1) Keep only the columns we need for aggregation\n","# 2) Group by Year + Quarter + Quarter name\n","# 3) Sum AnzBestWir over ALL demographic categories\n","#    (both sexes, both origins, all age groups)\n","#    -> this gives the TRUE population for each quarter-year.\n","# ============================================================\n","\n","# 1) Keep only the relevant columns from the January snapshot\n","population_jan_small = population_jan[[\n","    \"StichtagDatJahr\",   # year\n","    \"QuarCd\",            # quarter ID (numeric)\n","    \"QuarLang\",          # quarter name (string)\n","    \"AnzBestWir\"         # population count for each demographic slice\n","]]\n","\n","# 2) Aggregate to total population per (year, quarter)\n","population_year_quarter = (\n","    population_jan_small\n","    .groupby([\"StichtagDatJahr\", \"QuarCd\", \"QuarLang\"], as_index=False)\n","    .agg(total_population=(\"AnzBestWir\", \"sum\"))\n",")\n","\n","# Quick look at the result\n","population_year_quarter.head()\n"],"metadata":{"id":"3qYr_1fbVVWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["population_year_quarter.groupby(\"StichtagDatJahr\")[\"total_population\"].sum()\n"],"metadata":{"id":"2pG0OI1fcfsE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sanity Check"],"metadata":{"id":"sTdRDt05dYHy"}},{"cell_type":"code","source":["# ============================================================\n","# 3B.7 Check for Missing Values and Duplicates in Final Dataset\n","# This is important before saving the clean dataset to disk.\n","#\n","# We check:\n","# - Missing values in any column\n","# - Total number of duplicated rows\n","# - Dataset size (rows, columns)\n","# ============================================================\n","\n","print(\"=== CHECK MISSING VALUES ===\\n\")\n","print(population_year_quarter.isna().sum())\n","\n","print(\"\\n=== CHECK DUPLICATED ROWS ===\\n\")\n","dup_count = population_year_quarter.duplicated().sum()\n","print(\"Number of duplicated rows:\", dup_count)\n","\n","print(\"\\n=== DATASET SHAPE ===\")\n","print(\"Rows:\", population_year_quarter.shape[0])\n","print(\"Columns:\", population_year_quarter.shape[1])\n"],"metadata":{"id":"zKlxHc5nda9c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# 3Save Cleaned Population Dataset\n","#\n","# This file will be used in:\n","#  - Tableau visualizations\n","#  - Spatial join with Zurich quarters\n","#  - Merging with traffic data\n","#  - Stress Index calculation\n","# ============================================================\n","\n","save_path = PROC / \"population_year_quarter_clean.csv\"\n","population_year_quarter.to_csv(save_path, index=False)\n","\n","print(\"Clean population dataset saved to:\")\n","print(save_path)\n"],"metadata":{"id":"NdkywkfreUfE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RfDlUKJsEOPt"},"source":["### Quartier Data"]},{"cell_type":"code","source":["# ============================================================\n","# 3C.1 Load Quartier Lookup Dataset\n","# This dataset maps addresses / GWR IDs to:\n","#  - statistisches_quartier (quarter)\n","#  - stadtkreis (district)\n","#  - address information\n","# ============================================================\n","\n","quartier_path = RAW / \"str_stadtquartier_raw_for_join.csv\"\n","\n","quartiers = pd.read_csv(quartier_path)\n","\n","print(\"Quartier dataset loaded.\")\n","print(\"Shape:\", quartiers.shape)\n","quartiers.head()\n"],"metadata":{"id":"ulraIBp3fNzU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Selecting Relevant Columns"],"metadata":{"id":"gDQcFWQwgW3Q"}},{"cell_type":"code","source":["# ================================================\n","# 3C.2 Keep Only Relevant Quartier Columns\n","#  - gwr_egid: building ID (sometimes useful for merges)\n","#  - adresse: optional for labels\n","#  - stadtkreis: district ID\n","#  - statistisches_quartier: quarter name\n","# ================================================\n","\n","quartier_clean = quartiers[[\n","    \"gwr_egid\",\n","    \"adresse\",\n","    \"stadtkreis\",\n","    \"statistisches_quartier\"\n","]].copy()\n","\n","quartier_clean.head()\n"],"metadata":{"id":"HZDvuht0gKRp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sanity Check"],"metadata":{"id":"evsLaYMfgO4G"}},{"cell_type":"code","source":["# ============================================================\n","# 3C.3 Sanity Check for Quartier Lookup (clean version)\n","# Checks:\n","#   - Missing values per column\n","#   - Number of duplicated rows\n","#   - Final dataset shape\n","# ============================================================\n","\n","print(\"=== SANITY CHECK: Quartier Lookup Dataset ===\\n\")\n","\n","# 1) Missing values per column\n","missing = quartier_clean.isna().sum()\n","print(\">> Missing values per column:\\n\")\n","print(missing)\n","print(\"\\n\")\n","\n","# 2) Duplicate rows\n","duplicates = quartier_clean.duplicated().sum()\n","print(\">> Number of duplicated rows:\", duplicates)\n","print(\"\\n\")\n","\n","# 3) Dataset shape\n","rows, cols = quartier_clean.shape\n","print(\">> Dataset shape:\")\n","print(f\"Rows: {rows}\")\n","print(f\"Columns: {cols}\")\n","\n","print(\"\\n=== Sanity Check Completed ===\")\n"],"metadata":{"id":"JF4MS2CDgROH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# 3C.4 Save Clean Quartier Dataset\n","# This makes the dataset ready for merging and visualization\n","# ============================================================\n","\n","# Define save path\n","SAVE_DIR = \"/content/drive/MyDrive/Colab Notebooks/GEO Spatial Data Analysis/Data/processed/\"\n","quartier_save_path = SAVE_DIR + \"quartier_clean.csv\"\n","\n","# Save the dataframe\n","quartier_clean.to_csv(quartier_save_path, index=False)\n","\n","print(\"Quartier dataset saved successfully at:\")\n","print(quartier_save_path)\n"],"metadata":{"id":"MQ3IPSPkg516"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Quartier Shape File"],"metadata":{"id":"-_2uXNM5-136"}},{"cell_type":"code","source":["RAW = \"/content/drive/MyDrive/Colab Notebooks/GEO Spatial Data Analysis/Data/raw/\"\n","\n","# See what is inside the raw folder\n","!ls \"$RAW\"\n"],"metadata":{"id":"EnnBOoKb_hDV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["QUARTER_DIR = RAW + \"Stadtkreise_und_Quartiere_Zurich_und_Winterthur_-OGD/\"\n","\n","# List all files in that folder\n","!ls \"$QUARTER_DIR\"\n"],"metadata":{"id":"KQE6F_XF_bWY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import geopandas as gpd\n","\n","quartier_shp = QUARTER_DIR + \"UP_STADTQUARTIERE_F.shp\"\n","\n","quarters = gpd.read_file(quartier_shp)\n","\n","print(\"Loaded quarter shapefile!\")\n","print(\"Shape:\", quarters.shape)\n","print(quarters.columns)\n","\n","quarters.head()\n"],"metadata":{"id":"qihWR6-E-5LK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Quarter Mapping"],"metadata":{"id":"kFEvk8rOGBwc"}},{"cell_type":"code","source":["import geopandas as gpd\n","\n","# You already have this:\n","# quarters = gpd.read_file(quartier_shp)\n","\n","# Keep only Zurich (not Winterthur)\n","quarters_zurich = quarters[quarters[\"GEMEINDENA\"] == \"Zürich\"].copy()\n","print(\"Zurich quarters:\", quarters_zurich.shape)\n","\n","# Ensure CRS is LV95\n","print(\"Quarters CRS before:\", quarters_zurich.crs)\n","if quarters_zurich.crs is None:\n","    quarters_zurich = quarters_zurich.set_crs(epsg=2056)\n"],"metadata":{"id":"sI_J4zfAF0i7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading the Clean Version"],"metadata":{"id":"voNKVBhshBIA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8ps4rW8ESSL"},"outputs":[],"source":["# ==========================================================\n","# LOAD ALL CLEANED DATASETS FROM /processed FOLDER\n","# ==========================================================\n","\n","\n","BASE = \"/content/drive/MyDrive/Colab Notebooks/GEO Spatial Data Analysis/Data/processed/\"\n","\n","traffic_clean_path = BASE + \"traffic_clean_small.csv\"\n","population_clean_path = BASE + \"population_year_quarter_clean.csv\"\n","quartier_clean_path = BASE + \"quartier_clean.csv\"\n","\n","# Load them\n","traffic_clean = pd.read_csv(traffic_clean_path)\n","population_clean = pd.read_csv(population_clean_path)\n","quartier_clean = pd.read_csv(quartier_clean_path)\n","\n","print(\"Datasets loaded successfully.\\n\")\n","\n","print(\"Traffic shape:\", traffic_clean.shape)\n","print(\"Population shape:\", population_clean.shape)\n","print(\"Quartier shape:\", quartier_clean.shape)\n","\n","print(\"=== TRAFFIC CLEAN (HEAD) ===\")\n","display(traffic_clean.head())\n","\n","print(\"\\n=== POPULATION CLEAN (HEAD) ===\")\n","display(population_clean.head())\n","\n","print(\"\\n=== QUARTIER CLEAN (HEAD) ===\")\n","display(quartier_clean.head())\n"]},{"cell_type":"markdown","source":["## Merging Dataset"],"metadata":{"id":"1YwgqYisv1TC"}},{"cell_type":"markdown","source":["Quartier Mapping"],"metadata":{"id":"Zm0rRAWfG-KF"}},{"cell_type":"markdown","source":["### Quarter Mapping via Spatial Join\n","\n","Goal: Assign each traffic measurement site to a statistical quarter so that we can later aggregate\n","traffic volumes per quarter and year.\n","\n","Inputs:\n","- `traffic` (cleaned traffic data with `measurement_site_id`, `east_coordinate`, `north_coordinate`)\n","- `quarters_zurich` (GeoDataFrame with quarter polygons from `UP_STADTQUARTIERE_F.shp`)\n","\n","Method:\n","1. Extract all **unique measurement sites** and their coordinates.\n","2. Convert the sites to a GeoDataFrame in the Swiss coordinate system LV95 (EPSG:2056).\n","\n","1.   List item\n","2.   List item\n","\n","\n","3. Use a **spatial join** (`gpd.sjoin`) between the sites and the quarter polygons.\n","4. This assigns each site to a quarter name (`QUARTIERNA`) and quarter number (`QUARTIERNR`).\n","\n","Output:\n","- `sites_with_quarter`: GeoDataFrame with one row per measurement site and its assigned quarter.\n"],"metadata":{"id":"GHkdfHewHYs7"}},{"cell_type":"code","source":["\n","print(\"=== Traffic Columns ===\")\n","print(traffic.columns)\n","print(\"\\nTraffic preview:\")\n","display(traffic.head())\n","\n","print(\"\\n=== Quartier Columns ===\")\n","print(quartier.columns)\n","print(\"\\nQuartier preview:\")\n","display(quartier.head())\n","\n","print(\"\\n=== Population Columns ===\")\n","print(population.columns)\n","print(\"\\nPopulation preview:\")\n","display(population.head())\n"],"metadata":{"id":"cYWN30698OBV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Keep only needed columns from Zurich quarters\n","quarters_slim = quarters_zurich[[\"QUARTIERNA\", \"QUARTIERNU\", \"geometry\"]]\n","\n","# Spatial join: assign each site to a quarter\n","sites_with_quarter = gpd.sjoin(\n","    gdf_sites,\n","    quarters_slim,\n","    how=\"left\",\n","    predicate=\"within\"\n",")\n","\n","print(\"Sites with quarter info:\", sites_with_quarter.shape)\n","sites_with_quarter.head()\n"],"metadata":{"id":"d_-mdKfQGk14"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"nBWaLZKJHig0"}},{"cell_type":"code","source":["# Create a clean site → quarter mapping and merge into full traffic data\n","\n","# 5.1 Make a clean mapping table (drop geometry + index from spatial join)\n","sites_quarter_map = (\n","    sites_with_quarter\n","    .drop(columns=[\"geometry\", \"index_right\"])\n","    .rename(columns={\"QUARTIERNA\": \"quarter_name\",\n","                     \"QUARTIERNU\": \"quarter_id\"})\n",")\n","\n","print(\"Site → quarter mapping:\")\n","display(sites_quarter_map.head())\n","\n","# 5.2 Merge the mapping back into the full traffic dataset\n","traffic_q = traffic.merge(\n","    sites_quarter_map[[\"measurement_site_id\", \"quarter_name\", \"quarter_id\"]],\n","    on=\"measurement_site_id\",\n","    how=\"left\"\n",")\n","\n","print(\"Traffic with quarter info:\", traffic_q.shape)\n","display(traffic_q.head())\n"],"metadata":{"id":"TC2yuv-iHkFv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Saving The Qauartier Data with the Quarter Information"],"metadata":{"id":"etvUJLs0IINy"}},{"cell_type":"code","source":["\n","#  Save the enriched traffic dataset with quarter information\n","output_path = BASE + \"traffic_with_quarters.csv\"\n","\n","traffic_q.to_csv(output_path, index=False)\n","\n","print(\"Saved enriched traffic dataset to:\", output_path)\n"],"metadata":{"id":"YZR7O8rXIPHa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Aggreate Yearly Traffic per Quarter"],"metadata":{"id":"XHmXgZD8Jxjl"}},{"cell_type":"markdown","source":[" **Aggregate Yearly Traffic per Quarter**\n","\n","Goal: Compute the total annual traffic volume for each statistical quarter.\n","\n","Input:\n","- `traffic_q`: enriched traffic dataset  \n","  (one row per measurement event with `vehicle_count`, `timestamp`, `quarter_name`, `quarter_id`)\n","\n","Method:\n","1. Convert `timestamp` to a datetime object and extract the calendar year.\n","2. Group by `quarter_name`, `quarter_id`, and `year`.\n","3. Sum `vehicle_count` within each group to obtain `total_traffic`.\n","\n","Output:\n","- `traffic_qy`: table with one row per (quarter, year) and the corresponding `total_traffic`.\n","- This table will later be merged with the population dataset to compute growth rates and the Stress Index.\n"],"metadata":{"id":"giGHjJADKCHO"}},{"cell_type":"code","source":["# Aggregate yearly traffic per quarter\n","\n","import pandas as pd\n","\n","# 7.1 Ensure timestamp is datetime and create a 'year' column\n","traffic_q[\"timestamp\"] = pd.to_datetime(traffic_q[\"timestamp\"], errors=\"coerce\")\n","\n","# Drop rows where timestamp could not be parsed (if any)\n","before_drop = traffic_q.shape[0]\n","traffic_q = traffic_q.dropna(subset=[\"timestamp\"])\n","after_drop = traffic_q.shape[0]\n","\n","print(f\"Dropped {before_drop - after_drop} rows with invalid timestamps.\")\n","\n","traffic_q[\"year\"] = traffic_q[\"timestamp\"].dt.year\n","\n","# 7.2 Aggregate total yearly traffic per quarter\n","traffic_qy = (\n","    traffic_q\n","    .groupby([\"quarter_name\", \"quarter_id\", \"year\"], as_index=False)[\"vehicle_count\"]\n","    .sum()\n","    .rename(columns={\"vehicle_count\": \"total_traffic\"})\n","    .sort_values([\"quarter_id\", \"year\"])\n",")\n","\n","print(\"Traffic per quarter & year:\", traffic_qy.shape)\n","display(traffic_qy.head(10))\n"],"metadata":{"id":"ou9M20UPJ3Q_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Merge Yearly Traffic with Yearly Population Data"],"metadata":{"id":"fvYwQ2HhKexb"}},{"cell_type":"markdown","source":["### Merge Yearly Traffic with Yearly Population Data\n","\n","Goal:\n","Combine the aggregated annual traffic per quarter (`traffic_qy`) with the annual population\n","per quarter (`population`) so that we can compute growth rates and the Stress Index.\n","\n","Matching keys:\n","- Quarter name: `traffic_qy.quarter_name` ↔ `population.QuarLang`\n","- Year: `traffic_qy.year` ↔ `population.StichtagDatJahr`\n","\n","Output:\n","A unified dataset (`traffic_pop`) containing:\n","- quarter_name\n","- quarter_id\n","- year\n","- total_traffic\n","- total_population\n"],"metadata":{"id":"8X7jS8UHKi5C"}},{"cell_type":"code","source":["# Prepare population dataset for merging\n","population_renamed = population.rename(\n","    columns={\n","        \"QuarLang\": \"quarter_name\",\n","        \"StichtagDatJahr\": \"year\"\n","    }\n",")\n","\n","# Merge traffic totals with population totals\n","traffic_pop = traffic_qy.merge(\n","    population_renamed[[\"quarter_name\", \"year\", \"total_population\"]],\n","    on=[\"quarter_name\", \"year\"],\n","    how=\"left\"\n",")\n","\n","print(\"Merged traffic + population dataset:\", traffic_pop.shape)\n","traffic_pop.head(10)\n"],"metadata":{"id":"NYtMI1g2KlBm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Compute Year-over-Year Growth Rates"],"metadata":{"id":"ZmYx0V2sK47I"}},{"cell_type":"markdown","source":["### Compute Year-over-Year Growth Rates\n","\n","Goal:\n","Calculate yearly growth for both traffic volume and population in each quarter.\n","\n","Method:\n","1. Sort the merged dataset by `quarter_id` and `year`.\n","2. Use `groupby` + `pct_change()` to compute the percentage change:\n","   - `traffic_growth_pct = pct_change(total_traffic)`\n","   - `population_growth_pct = pct_change(total_population)`\n","3. Multiply by 100 to convert to percentages.\n","\n","Output:\n","Two new columns:\n","- `traffic_growth_pct`\n","- `population_growth_pct`\n","\n","These will be used to compute the Stress Index in the next step.\n"],"metadata":{"id":"RdmJWHIbK7Tc"}},{"cell_type":"code","source":["#  Compute traffic and population growth\n","\n","# Ensure correct sorting\n","traffic_pop = traffic_pop.sort_values([\"quarter_id\", \"year\"])\n","\n","# Compute year-over-year growth\n","traffic_pop[\"traffic_growth_pct\"] = (\n","    traffic_pop.groupby(\"quarter_id\")[\"total_traffic\"].pct_change() * 100\n",")\n","\n","traffic_pop[\"population_growth_pct\"] = (\n","    traffic_pop.groupby(\"quarter_id\")[\"total_population\"].pct_change() * 100\n",")\n","\n","print(\"Growth columns added:\")\n","traffic_pop.head(10)\n"],"metadata":{"id":"zfHu9JCsK_jL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Computing the Stress Index"],"metadata":{"id":"JT-nIXabLd1E"}},{"cell_type":"markdown","source":["###  Compute the Stress Index\n","\n","The Stress Index measures whether traffic growth outpaces population growth:\n","$$\n","\\text{Stress Index} = \\text{traffic growth (\\%)} - \\text{population growth (\\%)}\n","$$\n","Interpretation:\n","- **Positive values:** Traffic grows faster → more external inflow → *Commuter Hub*\n","- **Negative values:** Population grows faster → streets used more by residents → *Residential Zone*\n","- **Near zero:** Traffic and population change together → *Balanced*\n"],"metadata":{"id":"01hldVZhLhin"}},{"cell_type":"code","source":["# Compute Stress Index\n","traffic_pop[\"stress_index\"] = (\n","    traffic_pop[\"traffic_growth_pct\"] - traffic_pop[\"population_growth_pct\"]\n",")\n","\n","print(\"Stress Index added:\")\n","traffic_pop.head(10)\n"],"metadata":{"id":"1lBDQgKZLx8c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["• Stress Index = Traffic Growth (%) – Population Growth (%)\n","\n","• Positive Stress Index → traffic grows faster than population\n","  * Example: 2013 in Rathaus\n","    - Traffic growth: +3.59%\n","    - Population growth: +0.83%\n","    - Stress Index: +2.77% → indicates more commuter pressure\n","\n","• Negative Stress Index → population grows faster or traffic drops\n","  * Example: 2015 in Rathaus\n","    - Traffic growth: –37.83%\n","    - Population growth: +0.82%\n","    - Stress Index: –38.65% → reflects a major traffic decline (construction or route changes)\n","\n","• Very large positive Stress Index → strong traffic rebound or sudden inflow\n","  * Example: 2016 in Rathaus\n","    - Traffic growth: +57.58%\n","    - Population growth: –0.78%\n","    - Stress Index: +58.36% → could be heavy commuter influence or after construction work is done\n","\n","• Near-zero Stress Index → traffic and population change together\n","   * Example: 2021 in Rathaus\n","    - Traffic growth: +2.52%\n","    - Population growth: +0.86%\n","    - Stress Index: +1.67% → relatively balanced\n","\n","• Population growth is stable each year (around +0.6% to +1%)\n","• Traffic growth is highly volatile due to real-world factors:\n","  - roadworks\n","  - closures\n","  - sensor outages\n","  - seasonal variation\n","  - COVID impact (e.g., 2020 shows reduced traffic)\n","\n","• Stress Index values in the dataset follow realistic patterns and confirm:\n","  - traffic does not behave like population\n","  - commuter flows strongly affect certain quarters\n","  - volatility in traffic explains extreme stress values\n"],"metadata":{"id":"xugk5ftUM8Y-"}},{"cell_type":"markdown","source":["## Final Dataset Export for Tableau"],"metadata":{"id":"ldzwMdyWOryE"}},{"cell_type":"code","source":["traffic_pop_export = traffic_pop.rename(columns={\n","    \"quarter_name\": \"quarter\",\n","    \"quarter_id\": \"quarter_id\",\n","    \"year\": \"year\",\n","    \"total_traffic\": \"total_traffic\",\n","    \"total_population\": \"total_population\",\n","    \"traffic_growth_pct\": \"traffic_growth_pct\",\n","    \"population_growth_pct\": \"population_growth_pct\",\n","    \"stress_index\": \"stress_index\",\n","    \"category\": \"category\"\n","})\n"],"metadata":{"id":"l9Lx4uZAO0Dr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["export_path = BASE + \"stress_index_tableau_ready.csv\"\n","\n","traffic_pop_export.to_csv(export_path, index=False)\n","\n","print(\"Exported Tableau dataset to:\", export_path)\n"],"metadata":{"id":"bi_2nBCgO4DQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_export = pd.read_csv(BASE + \"stress_index_tableau_ready.csv\")\n","df_export.head(20)\n"],"metadata":{"id":"x6KKs-2OMzTC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Classify Quarters Based on Stress Index (Optional)\n","\n","To make the Stress Index easier to interpret and visualize, we classify each quarter–year\n","combination into three categories:\n","\n","- Commuter Hub: Stress Index > +5  \n","- Residential Zone: Stress Index < –5  \n","- Balanced: Stress Index between –5 and +5  \n","\n","This classification helps identify which quarters experience mobility pressure from commuters,\n","which are more residential, and which remain stable. This enhances storytelling and supports\n","clear thematic mapping in Tableau."],"metadata":{"id":"GGIToSitQ_LX"}},{"cell_type":"code","source":["# Create a classification based on Stress Index\n","\n","def classify_stress(x):\n","    if x > 5:\n","        return \"Commuter Hub\"\n","    elif x < -5:\n","        return \"Residential Zone\"\n","    else:\n","        return \"Balanced\"\n","\n","df_export[\"category\"] = df_export[\"stress_index\"].apply(classify_stress)\n","\n","print(\"Classification added:\")\n","df_export.head(20)\n"],"metadata":{"id":"KRdxOLLdRHC5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Classification shows which quarters are commuter hubs, residential zones, or balanced.**\n","* Commuter Hubs: quarters where stress index exceeds +5, indicating traffic growth far above population growth.\n","* Residential Zones: stress index below –5, where population grows faster or traffic drops.\n","* Balanced Quarters: stress index between –5 and +5, indicating stable mobility patterns.\n","* This classification improves the thematic map and helps identify pressure points in the city's mobility network.\n"],"metadata":{"id":"QIdlb2MJRStl"}},{"cell_type":"code","source":["# Create a new export dataset including the classification column\n","traffic_pop_export_classes = traffic_pop.rename(columns={\n","    \"quarter_name\": \"quarter\",\n","    \"quarter_id\": \"quarter_id\",\n","    \"year\": \"year\",\n","    \"total_traffic\": \"total_traffic\",\n","    \"total_population\": \"total_population\",\n","    \"traffic_growth_pct\": \"traffic_growth_pct\",\n","    \"population_growth_pct\": \"population_growth_pct\",\n","    \"stress_index\": \"stress_index\",\n","    \"category\": \"category\"\n","})\n","\n","# New file path\n","export_path_classes = BASE + \"stress_index_tableau_with_classes.csv\"\n","\n","# Save to disk\n","traffic_pop_export_classes.to_csv(export_path_classes, index=False)\n","\n","print(\"Exported classified Tableau dataset to:\", export_path_classes)\n"],"metadata":{"id":"ckUd504AR7Ke"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}